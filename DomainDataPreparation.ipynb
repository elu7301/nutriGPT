{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b11c84f-6dc4-4cf1-ad35-44f0243cda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91b758-26cd-4ed1-9400-7aa27508ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_DIR = \"./domain_pdf\"\n",
    "TXT_DIR = \"./domain_txt\"\n",
    "DATASET_DIR = \"./domain_dataset\"\n",
    "\n",
    "os.makedirs(TXT_DIR, exist_ok=True)\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae1840-6065-4144-9912-72f87c326051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_txt(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Извлекает текст из PDF-файла, используя PyMuPDF (fitz).\n",
    "    Возвращает сырой текст со всех страниц файла.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4cbac-f358-4836-9532-e30e5a8ac815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Очищает входной текст от:\n",
    "      - лишних переносов строк\n",
    "      - URL-ссылок (http/https)\n",
    "      - HTML-тегов (<...>)\n",
    "      - ссылок-цитат вида [1], [2]\n",
    "      - непечатаемых и управляющих символов\n",
    "      - множественных пробелов\n",
    "      - символов вне разрешённого набора\n",
    "      - лишних пробелов перед знаками препинания\n",
    "    Возвращает очищенный текст.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\r\\n', '\\n', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    text = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r\"[^А-Яа-яёЁA-Za-z0-9.,:;!?()\\-\\'\\\"\\s]\", '', text)\n",
    "    text = re.sub(r'\\s+([.,:;!?])', r'\\1', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02f2be-5470-43c6-b526-d2639034ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [f for f in os.listdir(PDF_DIR) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "all_texts = []\n",
    "total_chars_raw = 0\n",
    "total_chars_clean = 0\n",
    "\n",
    "for filename in tqdm(pdf_files, desc=\"Обработка PDF\"):\n",
    "    pdf_path = os.path.join(PDF_DIR, filename)\n",
    "    txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "    txt_path = os.path.join(TXT_DIR, txt_filename)\n",
    "\n",
    "    try:\n",
    "        raw_text = pdf_to_txt(pdf_path)\n",
    "        total_chars_raw += len(raw_text)\n",
    "\n",
    "        cleaned = clean_text(raw_text)\n",
    "        total_chars_clean += len(cleaned)\n",
    "\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned)\n",
    "\n",
    "        if cleaned.strip():\n",
    "            all_texts.append({\"text\": cleaned})\n",
    "        else:\n",
    "            print(f\"Пустой текст после очистки для файла: {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке файла {filename}: {e}\")\n",
    "\n",
    "print(\"\\n========== СТАТИСТИКА ==========\")\n",
    "print(f\"Всего PDF-файлов: {len(pdf_files)}\")\n",
    "print(f\"Общее кол-во символов ДО очистки: {total_chars_raw}\")\n",
    "print(f\"Общее кол-во символов ПОСЛЕ очистки: {total_chars_clean}\")\n",
    "print(f\"Общее кол-во записей для датасета: {len(all_texts)}\")\n",
    "print(\"================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d684f7-1d55-430b-a7cd-6a0d9773cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(all_texts)\n",
    "\n",
    "split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": split_dataset[\"train\"],\n",
    "    \"validation\": split_dataset[\"test\"]\n",
    "})\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205cf739-4740-42f4-9d7d-c041312a0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_to_disk(DATASET_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn-env",
   "language": "python",
   "name": "nn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
